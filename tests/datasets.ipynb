{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import create_session_config\n",
    "import tensorflow_probability as tp\n",
    "import numpy as np\n",
    "from models.utils import covariance,correlation_matrix,tf_cov,assert_cov_positive_definite,corr,print_tensor,print_tensors\n",
    "from models.nn_pdf_common import transform_x,density_estimator,create_pdf_layer_mv,create_partially_monotone_dense_layer,create_monotone_dense_layer\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from flags import FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.6760492 , -0.8348435 ],\n",
       "       [-1.4923203 , -7.115209  ],\n",
       "       [-0.74041617, -3.0240996 ],\n",
       "       [-1.6046643 , -5.3304253 ],\n",
       "       [-0.3412526 ,  1.7032733 ],\n",
       "       [-0.50675654,  5.0920806 ],\n",
       "       [ 0.47852707,  2.4016051 ],\n",
       "       [ 0.16629736,  0.7669723 ],\n",
       "       [ 1.4769595 ,  1.3136873 ],\n",
       "       [ 1.2968216 ,  7.886726  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.06036727,  -1.5030985 ],\n",
       "       [ -0.6623494 ,  -4.810568  ],\n",
       "       [  1.123797  ,   5.4944654 ],\n",
       "       [ -0.09942903,   0.5205032 ],\n",
       "       [  0.7757009 ,   7.214327  ],\n",
       "       [ -0.1510405 ,  -4.8452973 ],\n",
       "       [ -2.3672612 , -12.194161  ],\n",
       "       [ -0.08104871,   0.9206013 ],\n",
       "       [ -0.11757623,  -0.6340113 ],\n",
       "       [  0.05100786,   6.8053346 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.33647308,  0.87660855],\n",
       "       [ 0.8727094 ,  5.163147  ],\n",
       "       [ 0.30894616, -3.428802  ],\n",
       "       [-1.7385359 , -8.656099  ],\n",
       "       [ 0.8486311 ,  9.845854  ],\n",
       "       [ 0.3672291 , -1.4360477 ],\n",
       "       [ 0.6900572 ,  1.2616466 ],\n",
       "       [-0.34113094, -1.0779765 ],\n",
       "       [ 0.6137108 , 12.4429455 ],\n",
       "       [ 1.2336274 , -3.130633  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  8.],\n",
       "       [ 9., 10.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "corr_coef = 0.7\n",
    "corr_ = np.array([[1.0,corr_coef],[corr_coef,1.0]], dtype=np.float32)\n",
    "std_dev = np.array([[1.0,0.0],[0,5.0]], dtype=np.float32)\n",
    "true_cov = np.matmul(std_dev, np.matmul(corr_,std_dev))\n",
    "\n",
    "data_gen = tp.distributions.MultivariateNormalFullCovariance(loc=tf.constant([0.0] * 2),\n",
    "                                                                 covariance_matrix=tf.constant(true_cov))\n",
    "sample_op = data_gen.sample([10])\n",
    "    \n",
    "data_arr = np.array([[1.0,2.0],[3.0,4.0]], dtype=np.float32)\n",
    "dataset_arr = tf.data.Dataset.from_tensor_slices(data_arr)\n",
    "dataset_gen = tf.data.Dataset.from_tensors(sample_op)\n",
    "x_f=tf.placeholder(dtype=tf.float32, shape=[None,2])\n",
    "dataset_ph = tf.data.Dataset.from_tensors(x_f)\n",
    "\n",
    "iter = tf.data.Iterator.from_structure(dataset_arr.output_types)\n",
    "\n",
    "y = iter.get_next()\n",
    "# create the initialisation operations\n",
    "arr_init_op = iter.make_initializer(dataset_arr)\n",
    "gen_init_op = iter.make_initializer(dataset_gen)\n",
    "ph_init_op = iter.make_initializer(dataset_ph)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(arr_init_op) # switch to train dataset\n",
    "    sess.run(y)\n",
    "    sess.run(y)\n",
    "    sess.run(gen_init_op) # switch to val dataset\n",
    "    sess.run(y)\n",
    "    sess.run(gen_init_op) \n",
    "    sess.run(y)\n",
    "    sess.run(gen_init_op) \n",
    "    sess.run(y)\n",
    "    sess.run(ph_init_op, feed_dict={x_f:[[7.0,8.0],[9.0,10.0]]})\n",
    "    sess.run(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
